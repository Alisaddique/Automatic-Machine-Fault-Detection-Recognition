# Automatic-Machine-Fault-Detection-Recognition
Automatic Machine Fault Detection and Recognition  Project Description: This project aims to develop an automatic fault detection and recognition system for machines using computer vision techniques.
# Automatic Machine Fault Detection and Recognition

## Overview
Automatic Machine Fault Detection and Recognition is a project aimed at developing a system for identifying and categorizing faults in machines using audio signals. By leveraging computer vision techniques and machine learning models, the system can analyze audio signals generated by machines to detect various types of faults such as Arcing, Corona, Looseness, and Tracking. This project enhances maintenance practices, reduces downtime, and improves overall operational efficiency in industrial settings.

## Key Components
1. **Feature Extraction:** Features such as Mel-frequency cepstral coefficients (MFCC), chroma features, and mel spectrograms are extracted from the audio signals to characterize the underlying patterns.
2. **Model Development:** Convolutional neural network (CNN) models are trained on the extracted features to learn the patterns associated with different types of faults.
3. **Model Evaluation:** The trained models are evaluated using performance metrics such as accuracy, F1-score, ROC curves, and confusion matrices to assess their effectiveness in fault detection and recognition.
4. **Real-time Testing:** The system is capable of real-time testing, where it can classify faults in new audio samples captured from the machines during operation.

## Usage
To use the project, follow these steps:

1. **Clone the Repository:** Clone the GitHub repository to your local machine.
   ```
   git clone https://github.com/your_username/automatic-machine-fault-detection.git
   ```

2. **Install Dependencies:** Install the required dependencies by running the following command in your terminal.
   ```
   pip install -r requirements.txt
   ```

3. **Prepare Data:** Prepare your audio data by placing them in the `samples` directory within the repository. Ensure that the audio files are properly labeled.

4. **Run the Code:** Run the Jupyter Notebook or Python script provided in the repository to perform feature extraction, model training, evaluation, and testing.

5. **Test a Voice Sample:** Use the provided function `test_voice_sample` to test a voice sample and predict its class label based on the trained model.

## Directory Structure
```
├── samples/                  # Directory containing audio samples
├── automatic_fault_detection.ipynb   # Jupyter Notebook containing project code
├── README.md                 # Project README file
└── requirements.txt          # File containing project dependencies
```

## Contributors
- [Ali Saddique](https://github.com/Alisaddique)


## License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
